# ============================================================================
# Generic Exploratory Configuration Template
# ============================================================================
# Copy this to mybox-exploratory.yaml and customize for your CPU
# IMPORTANT: Detect your CPU topology first with: lscpu --parse=CPU,Core,Node
# ============================================================================

mode: exploratory
repetitions: 3

model_path: /path/to/your/model.gguf
model_info: "model-name-Q4_K_M"

# Builds to test - edit paths to match your setup
builds:
  build1:
    binary: /path/to/llama.cpp-build1/bin/llama-bench
    label: "Build 1 (baseline)"
    
  build2:
    binary: /path/to/llama.cpp-build2/bin/llama-bench
    label: "Build 2 (optimized)"

# Which builds to include in this run
builds_select:
  - build1
  - build2

# Test matrix - adapt CPU bindings to YOUR system
# Use: lscpu --parse=CPU,Core,Node to find your physical core IDs
test_matrix:
  # Test 1: All physical cores
  - name: "all_cores"
    numactl: "--physcpubind=<your_physical_cores>"  # e.g., 0,1,2,3,4,5,6,7
    env:
      OMP_NUM_THREADS: "<your_thread_count>"  # Match your core count
    extra_args: "-t <your_thread_count>"
    
  # Test 2: Single NUMA node
  - name: "node0_only"
    numactl: "--physcpubind=<node0_cores>"  # e.g., 0,1,2,3
    env:
      OMP_NUM_THREADS: "<your_thread_count>"
    extra_args: "-t <your_thread_count>"
    
  # Test 3: No NUMA pinning (baseline)
  - name: "vanilla"
    numactl: null
    env:
      OMP_NUM_THREADS: "<your_thread_count>"
    extra_args: "-t <your_thread_count>"

# Standard llama-bench metrics
metrics:
  - pp512    # Prompt processing: 512 tokens
  - tg128    # Text generation: 128 tokens
  - mixed    # Prompt=512 + Generate=128

# Output directory
output_dir: ./reports
