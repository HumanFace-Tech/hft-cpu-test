# ============================================================================
# EXAMPLE: Deep Mode - Parameter Sweep
# ============================================================================
# Use this AFTER exploratory identifies 2-3 winning builds
# Deep mode tests parameter variations on the winners
#
# This generates a HUGE matrix by combining:
# - builds × NUMA configs × KV cache × MLA × batch sizes × metrics
# ============================================================================

mode: deep
repetitions: 3  # Still reasonable reps, but breadth not depth

model_path: /path/to/your/model.gguf
model_info: "gpt-oss-20b-Q4_K_M"

# Builds from exploratory winners
builds:
  ik_vanilla:
    binary: /home/nikro/projects/ik_llama.cpp/build-cpu/bin/llama-bench
    label: "IK-vanilla (winner)"
    
  ik_fancy:
    binary: /home/nikro/projects/ik_llama.cpp/build-fancy/bin/llama-bench
    label: "IK-fancy (runner-up)"

builds_select:
  - ik_vanilla
  - ik_fancy

# Base NUMA/threading configs to test
test_matrix:
  - name: "numa_optimal"
    numactl: "-N 0,1 -m 0,1 --physcpubind=0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15"
    env:
      OMP_NUM_THREADS: "16"
    extra_args: "-t 16"
  
  - name: "numa_node0_only"
    numactl: "-N 0 -m 0 --physcpubind=0,1,2,3,4,5,6,7"
    env:
      OMP_NUM_THREADS: "8"
    extra_args: "-t 8"
  
  - name: "no_affinity"
    numactl: ""
    env:
      OMP_NUM_THREADS: "16"
    extra_args: "-t 16"

# Metrics to test
metrics:
  - pp512
  - tg128
  - mixed

# ============================================================================
# PARAMETER SWEEP CONFIGURATION (deep mode only)
# ============================================================================

parameter_sweep:
  
  # KV Cache Type Variations
  # Test different quantization for K and V caches
  kv_cache:
    - name: "f16_f16"
      args: "-ctk f16 -ctv f16"  # Default (baseline)
    
    - name: "f16_f8"
      args: "-ctk f16 -ctv f8"   # Quantize V cache
    
    - name: "f8_f16"
      args: "-ctk f8 -ctv f16"   # Quantize K cache
    
    - name: "f8_f8"
      args: "-ctk f8 -ctv f8"    # Quantize both (max memory savings)
  
  # MLA (Multi-Layer Attention) Variants
  # Test different attention optimizations
  mla_variants:
    - name: "baseline"
      args: ""  # No MLA flags
    
    - name: "mla2_fa_fmoe"
      args: "-mla 2 -fa -fmoe"  # MLA level 2 + flash attn + fused MoE
    
    - name: "mla3_fa_fmoe"
      args: "-mla 3 -fa -fmoe"  # MLA level 3 + flash attn + fused MoE
    
    - name: "mla2_fa"
      args: "-mla 2 -fa"  # MLA level 2 + flash attn (no fused MoE)
    
    - name: "mla3_fa"
      args: "-mla 3 -fa"  # MLA level 3 + flash attn (no fused MoE)
  
  # Batch/Ubatch Size Variations
  # Test different batching configurations
  batch_sizes:
    - name: "std_2048_512"
      args: "-b 2048 -ub 512"  # Default (baseline)
    
    - name: "small_256_32"
      args: "-b 256 -ub 32"    # Small batches (low latency)
    
    - name: "small_256_64"
      args: "-b 256 -ub 64"
    
    - name: "small_256_96"
      args: "-b 256 -ub 96"
    
    - name: "small_256_128"
      args: "-b 256 -ub 128"
    
    - name: "mid_512_128"
      args: "-b 512 -ub 128"   # Medium batches
    
    - name: "mid_1024_256"
      args: "-b 1024 -ub 256"

output_dir: ./reports

# ============================================================================
# MATRIX SIZE CALCULATION
# ============================================================================
# Total tests = builds × test_matrix × metrics × kv_cache × mla × batch_sizes
#
# With this config:
# 2 builds × 3 NUMA × 3 metrics × 4 KV × 5 MLA × 7 batch = 2,520 tests
# At 3 reps each = 7,560 runs
# 
# Estimated time: ~10-15 hours (depends on model size)
#
# TIP: Start smaller! Comment out most variants, test a few, then expand
# ============================================================================
